{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474500ed-a3fa-4d57-9f57-9a654e9b8d27",
   "metadata": {},
   "source": [
    "# 원래"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9cf14-9810-4f24-a324-c9d4169477ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.vectorized_documents = self.vectorizer.fit_transform([doc['article'] for doc in documents])\n",
    "        self.similarity_scores = {}\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]\n",
    "        \n",
    "        # ranked_indices와 함께 유사도 값도 반환\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "\n",
    "vector_space_model = VectorSpaceModel(documents)\n",
    "\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(query)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant with the keyword '{}':\".format(query))\n",
    "\n",
    "for idx, similarity in zip(ranked_indices[:500], ranked_similarities[:500]):\n",
    "    print(\"Title: \", documents[idx]['title'], documents[idx]['date'])\n",
    "    print(\"Similarity: \", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355c08f-8287-4ae6-96a7-78f3960fcced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import re\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.cluster import KMeans\n",
    "# from konlpy.tag import Okt\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import warnings\n",
    "\n",
    "# class VectorSpaceModel:\n",
    "#     def __init__(self, documents):\n",
    "#         self.documents = documents\n",
    "#         self.vectorizer = TfidfVectorizer()\n",
    "#         self.vectorized_documents = self.vectorizer.fit_transform([doc['article'] for doc in documents])\n",
    "#         self.similarity_scores = {}\n",
    "        \n",
    "#     def search(self, query):\n",
    "#         query_vector = self.vectorizer.transform([query])\n",
    "#         similarities = cosine_similarity(query_vector, self.vectorized_documents)\n",
    "#         ranked_indices = similarities.argsort()[0][::-1]\n",
    "        \n",
    "#         # ranked_indices와 함께 유사도 값도 반환\n",
    "#         ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "#         return ranked_indices, ranked_similarities\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.vectorized_documents = self.vectorizer.fit_transform([doc['article'] for doc in documents])\n",
    "\n",
    "    # def search(self, query):\n",
    "    #     query_vector = self.vectorizer.transform([query])\n",
    "    #     similarities = cosine_similarity(query_vector, self.vectorized_documents)        \n",
    "    #     positive_similarities_indices = similarities[0] > 0\n",
    "    #     ranked_indices = positive_similarities_indices.nonzero()[0]        \n",
    "    #     ranked_similarities = similarities[0][ranked_indices]        \n",
    "    #     ranked_indices = ranked_indices[ranked_similarities.argsort()[::-1]]\n",
    "    #     ranked_similarities = sorted(ranked_similarities, reverse=True)\n",
    "    #     return ranked_indices, ranked_similarities    \n",
    "\n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]\n",
    "        ranked_similarities = [idx for idx in ranked_indices if similarities[0][idx] > 0.0]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        return ranked_indices, ranked_similarities\n",
    "        \n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "\n",
    "vector_space_model = VectorSpaceModel(documents)\n",
    "\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(query)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant with the keyword '{}':\".format(query))\n",
    "\n",
    "for idx, similarity in zip(ranked_indices[:500], ranked_similarities[:500]):\n",
    "    print(\"Title: \", documents[idx]['title'], documents[idx]['date'])\n",
    "    print(\"Similarity: \", similarity)\n",
    "\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "\n",
    "save_search_result_to_csv(documents, ranked_indices, 'vec_ori.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0184d6-46d7-464f-a126-0ae13dfac5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranked_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f650a39-f686-4b59-90e3-dd87065335af",
   "metadata": {},
   "source": [
    "# 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdef61e-0415-4861-8dbf-caf686aba1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(query)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_제22대.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f24df6-8b74-43ef-99f6-aff7aa5f3bb2",
   "metadata": {},
   "source": [
    "# 쿼리도 전처리 조금 - stopwords 없애고 역시 한글만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eadfa1-1fd4-4394-a037-346b6eb3655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        self.komoran = Komoran()\n",
    "        #with open('datasets/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        #    self.stopwords = set(f.read().split(','))\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.strip()  \n",
    "        text = re.compile('<.*?>').sub('', text) \n",
    "        text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "        text = re.sub('\\s+', ' ', text)  \n",
    "        text = re.sub(r'[^\\w\\s]', ' ', str(text).strip())\n",
    "        text = re.sub(r'\\d', ' ', text) \n",
    "        text = re.sub(r'\\s+', ' ', text) \n",
    "        return text\n",
    "    \n",
    "    def is_korean(self, text):\n",
    "        # Check if the text contains Hangul characters only\n",
    "        korean_pattern = re.compile('[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣]+')\n",
    "        if korean_pattern.search(text):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def final(self, text):\n",
    "        n = []\n",
    "        word = self.komoran.nouns(text)\n",
    "        p = self.komoran.pos(text)\n",
    "        for pos in p:\n",
    "            if pos[1] in ['SL'] and self.is_korean(pos[0]):\n",
    "                word.append(pos[0])\n",
    "        for w in word:\n",
    "         #   if len(w) > 1 and w not in self.stopwords:\n",
    "            n.append(w)\n",
    "        return \" \".join(n)\n",
    "\n",
    "    def finalpreprocess(self, documents):\n",
    "        for doc in documents:\n",
    "            doc['article'] = self.final(self.preprocess(doc['article']))\n",
    "        return documents\n",
    "        \n",
    "preprocessor = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572326bb-0f3f-4cc0-8de1-c10cd943578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_선거.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9726e-38d1-43fa-a6e2-68087da5fb02",
   "metadata": {},
   "source": [
    "# 유사도 0.01 이상만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05524db-3437-44e8-a9da-441fa53d7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.01]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_410투표.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b1881-3d7b-48c4-9539-441f147b8601",
   "metadata": {},
   "source": [
    "# 유사도 0.05 이상만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a75f9-4680-42e2-984f-8238796504b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.05]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_제22대.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee13495-0b96-45db-bcd8-2e6c94e81e48",
   "metadata": {},
   "source": [
    "# 유사도 0.1 이상만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b0c3a-aba7-42cb-b20a-bf4283c23a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.1]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_선거.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772301d6-9784-4c2b-9f28-d9919a48d1bd",
   "metadata": {},
   "source": [
    "# 0.075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5647cb9-b64b-43fd-abcf-4e0320293cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.075]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_410투표.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f917ab6-8539-4920-9658-2dff3bace01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1c48a-7475-4ddf-b556-9d6968e09df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.12]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, 'Vector_선거.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f97083-3657-414c-a530-6777f21b25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  제22대 국회의원선거\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ Search results ]]\n",
      "Below are the articles relevant to the keyword '제22대 국회의원선거':\n",
      "Title: “참정권 행사 못 할 수도…” 선거인 명부 열람 24~26일\n",
      "Date: 2024/03/22 15:42\n",
      "Similarity: 0.9157079984487292\n",
      "\n",
      "Title: 내일부터 4·10총선 선거운동 시작…후보 관련글 SNS 공유 주의\n",
      "Date: 2024/03/27 10:23\n",
      "Similarity: 0.9060294843105663\n",
      "\n",
      "Title: 지방공사 상근직원 선거운동 금지 ‘위헌’…교회서 ‘금지’는 ‘합헌’\n",
      "Date: 2024/01/25 18:30\n",
      "Similarity: 0.8697277142264345\n",
      "\n",
      "Title: 총선 직전 유권자 대상 집회 개최…선관위, 후보·사무장 경찰 고발\n",
      "Date: 2024/04/06 21:05\n",
      "Similarity: 0.8653829746493353\n",
      "\n",
      "Title: 헌재, “○장로 속한 당 뽑아라” 목사 선거운동 불가…지방공사 직원은 가능\n",
      "Date: 2024/01/25 15:41\n",
      "Similarity: 0.8650936564864831\n",
      "\n",
      "Title: “푸바오 탈은 되지만 복장은 위반”…與野, 까다로운 선거법에 진땀\n",
      "Date: 2024/03/24 19:19\n",
      "Similarity: 0.8624896701642011\n",
      "\n",
      "Title: 중앙선관위 “이달 24~26일 총선 선거인명부 열람·이의신청”\n",
      "Date: 2024/03/22 15:19\n",
      "Similarity: 0.8614209445605282\n",
      "\n",
      "Title: “시각장애인도 선거 정보 쉽게”…선관위, 인권위 권고 수용\n",
      "Date: 2024/02/29 13:48\n",
      "Similarity: 0.8449213739037442\n",
      "\n",
      "Title: 선관위, 위법 선거문자 단속 강화…수신거부에도 발송시 엄중조치\n",
      "Date: 2024/02/22 13:24\n",
      "Similarity: 0.8335817751379645\n",
      "\n",
      "Title: 국민의힘 “이재명, 타 정당 후보 유세·꼼수 마이크…선거법위반 고발”\n",
      "Date: 2024/03/24 15:22\n",
      "Similarity: 0.8258219957038496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self, documents, vectorizer, svd, num_components=50):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = vectorizer\n",
    "        self.svd = svd\n",
    "        self.reduced_vectorized_documents = np.array([doc['vectors'] for doc in documents])\n",
    "        \n",
    "    def search(self, query):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        query_vector_reduced = self.svd.transform(query_vector)\n",
    "        similarities = cosine_similarity(query_vector_reduced, self.reduced_vectorized_documents)\n",
    "        ranked_indices = similarities.argsort()[0][::-1]        \n",
    "        ranked_indices = [idx for idx in ranked_indices if similarities[0][idx] > 0.12]\n",
    "        ranked_similarities = [similarities[0][idx] for idx in ranked_indices]\n",
    "        \n",
    "        return ranked_indices, ranked_similarities\n",
    "\n",
    "\n",
    "# Load documents from CSV\n",
    "documents = []\n",
    "with open('dataset/Korea_DB_0413.csv', mode='r', encoding='cp949') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        date = row['date']\n",
    "        documents.append({'title': title, 'date': date, 'article': article})\n",
    "preprocessed_documents = []\n",
    "with open('../datasets/preprocessed.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        article = row['article']\n",
    "        preprocessed_documents.append({'title': title, 'article': article})\n",
    "\n",
    "vectors, vectorizer, svd = vectorize(preprocessed_documents)\n",
    "# Create VectorSpaceModel instance with runcatedSVD\n",
    "for i in range(len(documents)):\n",
    "    documents[i]['vectors'] = vectors[i]\n",
    "        \n",
    "vector_space_model = VectorSpaceModel(documents, vectorizer, svd)\n",
    "# User query input\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Ignore FutureWarning from sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "preprocessor = Preprocess()\n",
    "pre_q = preprocessor.final(query)\n",
    "# Perform search and retrieve ranked indices with similarities\n",
    "ranked_indices, ranked_similarities = vector_space_model.search(pre_q)\n",
    "\n",
    "print(\"[[ Search results ]]\")\n",
    "print(\"Below are the articles relevant to the keyword '{}':\".format(query))\n",
    "\n",
    "# Display top results with titles, dates, and similarities\n",
    "num_results_to_display = 10  # Number of top results to display\n",
    "for idx, similarity in zip(ranked_indices[:num_results_to_display], ranked_similarities[:num_results_to_display]):\n",
    "    print(\"Title:\", documents[idx]['title'])\n",
    "    print(\"Date:\", documents[idx]['date'])\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()  # Print a blank line for separation\n",
    "\n",
    "def save_search_result_to_csv(documents, search_result, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Title', 'Date', 'Article'])\n",
    "        for doc_id in search_result:\n",
    "            doc = documents[doc_id]\n",
    "            writer.writerow([doc['title'], doc['date'], doc['article']])\n",
    "save_search_result_to_csv(documents, ranked_indices, '../datasets/Vector_제22대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c35715-a7e0-453b-876b-1a83d8323170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(preprocessed_documents, num_components=50):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorized_documents = vectorizer.fit_transform([doc['article'] for doc in preprocessed_documents])    \n",
    "        svd = TruncatedSVD(n_components=num_components)\n",
    "        reduced_vectorized_documents = svd.fit_transform(vectorized_documents)\n",
    "        return reduced_vectorized_documents, vectorizer, svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cffe5c-0392-48ec-a727-5ff677c3c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        self.komoran = Komoran()\n",
    "        #with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        #    self.stopwords = set(f.read().split(','))\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.strip()  \n",
    "        text = re.compile('<.*?>').sub('', text) \n",
    "        text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "        text = re.sub('\\s+', ' ', text)  \n",
    "        text = re.sub(r'[^\\w\\s]', ' ', str(text).strip())\n",
    "        text = re.sub(r'\\d', ' ', text) \n",
    "        text = re.sub(r'\\s+', ' ', text) \n",
    "        return text\n",
    "    \n",
    "    def final(self, text):\n",
    "        n = []\n",
    "        word = self.komoran.nouns(text)\n",
    "        p = self.komoran.pos(text)\n",
    "        for pos in p:\n",
    "            if pos[1] in ['SL']:\n",
    "                word.append(pos[0])\n",
    "        for w in word:\n",
    "            #if len(w) > 1 and w not in self.stopwords:\n",
    "            n.append(w)\n",
    "        return \" \".join(n)\n",
    "\n",
    "#     def finalpreprocess(self, documents):\n",
    "#         for doc in documents:\n",
    "#             doc['article'] = self.final(self.preprocess(doc['article']))\n",
    "#         return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385076eb-686f-4ba5-9812-540da73259be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
