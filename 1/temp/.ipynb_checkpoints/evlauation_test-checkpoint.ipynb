{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbacacab-902e-4219-ad7d-849aca55bd0d",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b53f997-8e7a-4e08-b75e-c91fec6131b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "query = []\n",
    "file_path = ['datasets/Boolean_문장.csv']\n",
    "\n",
    "for i in range(len(file_path)):\n",
    "    with open(file_path[i], mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for article in query:\n",
    "            writer.writerow([article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d28b89-6b31-4d2d-8a58-4d2148554ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def read_csv_to_dict(file_path, key_names):\n",
    "    result_dict = {}\n",
    "    for i, path in enumerate(file_path):\n",
    "        file_name = key_names[i]  \n",
    "        if os.path.isfile(path):\n",
    "            with open(path, mode='r', newline='', encoding='utf-8') as file:\n",
    "                reader = csv.reader(file)\n",
    "                titles = set()\n",
    "                dates = set()\n",
    "                for row in reader:\n",
    "                    titles.add(row[0])  # 첫 번째 col은 title\n",
    "                    if len(row) > 1:\n",
    "                        dates.add(row[1])\n",
    "                result_dict[file_name] = titles, dates\n",
    "        else:\n",
    "            print(f\"cannot find the file: {path}\")\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6978f40-088e-487f-a3f9-c34cef61233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = ['datasets/총선.csv', 'datasets/선거.csv', 'datasets/제22대_국회의원선거.csv', 'datasets/4월_10일_투표.csv', 'datasets/문장.csv']\n",
    "boolean_data = ['datasets/Boolean_총선.csv', 'datasets/Boolean_선거.csv', 'datasets/Boolean_제22대.csv', 'datasets/Boolean_410투표.csv', 'datasets/Boolean_문장.csv']\n",
    "vector_data = ['datasets/Vector_총선.csv', 'datasets/Vector_선거.csv', 'datasets/Vector_제22대.csv', 'datasets/Vector_410투표.csv', 'datasets/Vector_문장.csv']\n",
    "\n",
    "keys = ['총선', '선거', '제22대_국회의원선거', '4월_10일_투표', '문장']\n",
    "\n",
    "ground_truths = read_csv_to_dict(label_data, keys)\n",
    "boolean_results = read_csv_to_dict(boolean_data, keys)\n",
    "vector_results = read_csv_to_dict(boolean_data, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d8925be-9201-4bf7-a976-9b253a76b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def read_csv_to_dict(file_path, key_names):\n",
    "    result_dict = {}\n",
    "    for i, path in enumerate(file_path):\n",
    "        file_name = key_names[i]  \n",
    "        if os.path.isfile(path):\n",
    "            with open(path, mode='r', newline='', encoding='utf-8') as file:\n",
    "                reader = csv.reader(file)\n",
    "                titles = set()\n",
    "                dates = set()\n",
    "                for row in reader:\n",
    "                    title = row[0].strip()  # 첫 번째 col은 title\n",
    "                    titles.add(title)\n",
    "                    \n",
    "                    if len(row) > 1:\n",
    "                        date_with_time = row[1].strip()\n",
    "                        try:\n",
    "                            date_obj = datetime.strptime(date_with_time, \"%Y/%m/%d %H:%M\")\n",
    "                            date_only = date_obj.strftime(\"%Y/%m/%d\")  # 시간 부분 제거\n",
    "                            dates.add(date_only)\n",
    "                        except ValueError:\n",
    "                            print(f\"Ignoring invalid date format: {date_with_time}\")\n",
    "                \n",
    "                result_dict[file_name] = titles, dates\n",
    "        else:\n",
    "            print(f\"Cannot find the file: {path}\")\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "314466e1-d0a2-49b4-ab9f-9d598078c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n"
     ]
    }
   ],
   "source": [
    "label_data = ['datasets/총선.csv', 'datasets/선거.csv', 'datasets/제22대_국회의원선거.csv', 'datasets/4월_10일_투표.csv', 'datasets/문장.csv']\n",
    "#boolean_data = ['datasets/Boolean_총선.csv', 'datasets/Boolean_선거.csv', 'datasets/Boolean_제22대.csv', 'datasets/Boolean_410투표.csv', 'datasets/Boolean_문장.csv']\n",
    "vector_data = ['datasets/Vector_총선.csv', 'datasets/Vector_선거.csv', 'datasets/Vector_제22대.csv', 'datasets/Vector_410투표.csv', 'datasets/Vector_문장.csv']\n",
    "\n",
    "keys = ['총선', '선거', '제22대_국회의원선거', '4월_10일_투표', '문장']\n",
    "\n",
    "ground_truths = read_csv_to_dict(label_data, keys)\n",
    "#boolean_results = read_csv_to_dict(boolean_data, keys)\n",
    "vector_results = read_csv_to_dict(vector_data, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3437f14-e3a5-4af6-b39e-92da11394d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n"
     ]
    }
   ],
   "source": [
    "label_data = ['datasets/총선.csv']\n",
    "vector_data = ['vec_ori.csv']         \n",
    "vector_2 = ['vec_2.csv']   \n",
    "keys = ['총선']\n",
    "\n",
    "ground_truths = read_csv_to_dict(label_data, keys)\n",
    "vector = read_csv_to_dict(vector_data, keys)\n",
    "vector_2 = read_csv_to_dict(vector_2, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b0f56-8437-41fa-b1c0-9450886168b1",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de42008c-b623-46bf-82e3-ab5e92f49a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. precision\n",
    "# 2. recall\n",
    "# 3. f1 score\n",
    "# 4. average\n",
    "def calculate_precision_recall(ground_truth, model_results):\n",
    "    true_positives = ground_truth.intersection(model_results)\n",
    "    precision = len(true_positives) / len(model_results) if model_results else 0\n",
    "    recall = len(true_positives) / len(ground_truth) if ground_truth else 0\n",
    "    return precision, recall\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3691ec70-4b19-4b90-bc2e-0b601857c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = set(ground_truths['총선'][0])\n",
    "vector = set(vector['총선'][0])  \n",
    "vector2 = set(vector_2['총선'][0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "232312b0-5483-4e0a-98a4-563004634ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "\n",
    "precision_2, recall_2 = calculate_precision_recall(gt, vector2)\n",
    "f1_score_2 = calculate_f1_score(precision_2, recall_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b9af03f-86d6-495a-8209-e12615ceb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41483870967741937 1.0 0.5864113087095304\n",
      "0.5297187590605973 0.9471228615863142 0.6794347341018966\n"
     ]
    }
   ],
   "source": [
    "print(precision_v, recall_v, f1_score_v)\n",
    "print(precision_2, recall_2, f1_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "802887be-b4ae-4214-aa97-822616ca0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "654b0816-3015-42d8-a312-76eb08e87057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result of vector model [ '총선' ] ====================\n",
      "Precision: 0.52, Recall: 0.95\n",
      "F1 Score: 0.67\n",
      "\n",
      "==================== result of vector model [ '선거' ] ====================\n",
      "Precision: 0.46, Recall: 0.86\n",
      "F1 Score: 0.60\n",
      "\n",
      "==================== result of vector model [ '제22대_국회의원선거' ] ====================\n",
      "Precision: 0.05, Recall: 0.98\n",
      "F1 Score: 0.09\n",
      "\n",
      "==================== result of vector model [ '4월_10일_투표' ] ====================\n",
      "Precision: 0.01, Recall: 0.95\n",
      "F1 Score: 0.01\n",
      "\n",
      "==================== result of vector model [ '문장' ] ====================\n",
      "Precision: 0.00, Recall: 1.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Average Precision of vector model: 0.21\n",
      "Average Recall of vector model: 0.95\n",
      "Average F1 Score of vector model: 0.27\n"
     ]
    }
   ],
   "source": [
    "results_b, results_v = [], []\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    gt = set(ground_truths[key][0])\n",
    "    #boolean = set(boolean_results[key][0])\n",
    "    vector = set(vector_results[key][0])  \n",
    "\n",
    "    # boolean model\n",
    "    # precision_b, recall_b = calculate_precision_recall(gt, boolean)\n",
    "    # f1_score_b = calculate_f1_score(precision_b, recall_b)\n",
    "    # print(f\"==================== result of boolean model [ '{key}' ] ====================\")\n",
    "    # print(f\"Precision: {precision_b:.2f}, Recall: {recall_b:.2f}\")\n",
    "    # print(f\"F1 Score: {f1_score_b:.2f}\\n\")\n",
    "    # results_b.append((precision_b, recall_b, f1_score_b))\n",
    "\n",
    "    # vector model\n",
    "    precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "    f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "    print(f\"==================== result of vector model [ '{key}' ] ====================\")\n",
    "    print(f\"Precision: {precision_v:.2f}, Recall: {recall_v:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score_v:.2f}\\n\")\n",
    "    results_v.append((precision_v, recall_v, f1_score_v))\n",
    "\n",
    "# Average for boolean model\n",
    "# average_precision_b = sum([result[0] for result in results_b]) / len(results_b)\n",
    "# average_recall_b = sum([result[1] for result in results_b]) / len(results_b)\n",
    "# average_f1_score_b = sum([result[2] for result in results_b]) / len(results_b)\n",
    "\n",
    "# print(f\"Average Precision of boolean model: {average_precision_b:.2f}\")\n",
    "# print(f\"Average Recall of boolean model: {average_recall_b:.2f}\")\n",
    "# print(f\"Average F1 Score of boolean model: {average_f1_score_b:.2f}\\n\")\n",
    "\n",
    "# average_results_b = [average_precision_b, average_recall_b, average_f1_score_b]\n",
    "\n",
    "# Average for vector model\n",
    "average_precision_v = sum([result[0] for result in results_v]) / len(results_v)\n",
    "average_recall_v = sum([result[1] for result in results_v]) / len(results_v)\n",
    "average_f1_score_v = sum([result[2] for result in results_v]) / len(results_v)\n",
    "\n",
    "print(f\"Average Precision of vector model: {average_precision_v:.2f}\")\n",
    "print(f\"Average Recall of vector model: {average_recall_v:.2f}\")\n",
    "print(f\"Average F1 Score of vector model: {average_f1_score_v:.2f}\")\n",
    "\n",
    "average_results_v = [average_precision_v, average_recall_v, average_f1_score_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e381bc5-eacf-4a1a-a856-f092024f64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "767ea27c-0061-45f6-a161-6016dfb9c0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result of vector model [ '총선' ] ====================\n",
      "Precision: 0.50, Recall: 0.98\n",
      "F1 Score: 0.66\n",
      "\n",
      "==================== result of vector model [ '선거' ] ====================\n",
      "Precision: 0.45, Recall: 0.91\n",
      "F1 Score: 0.60\n",
      "\n",
      "==================== result of vector model [ '제22대_국회의원선거' ] ====================\n",
      "Precision: 0.05, Recall: 0.99\n",
      "F1 Score: 0.09\n",
      "\n",
      "==================== result of vector model [ '4월_10일_투표' ] ====================\n",
      "Precision: 0.01, Recall: 0.90\n",
      "F1 Score: 0.01\n",
      "\n",
      "==================== result of vector model [ '문장' ] ====================\n",
      "Precision: 0.00, Recall: 1.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Average Precision of vector model: 0.20\n",
      "Average Recall of vector model: 0.96\n",
      "Average F1 Score of vector model: 0.27\n"
     ]
    }
   ],
   "source": [
    "results_b, results_v = [], []\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    gt = set(ground_truths[key][0])\n",
    "    #boolean = set(boolean_results[key][0])\n",
    "    vector = set(vector_results[key][0])  \n",
    "\n",
    "    # boolean model\n",
    "    # precision_b, recall_b = calculate_precision_recall(gt, boolean)\n",
    "    # f1_score_b = calculate_f1_score(precision_b, recall_b)\n",
    "    # print(f\"==================== result of boolean model [ '{key}' ] ====================\")\n",
    "    # print(f\"Precision: {precision_b:.2f}, Recall: {recall_b:.2f}\")\n",
    "    # print(f\"F1 Score: {f1_score_b:.2f}\\n\")\n",
    "    # results_b.append((precision_b, recall_b, f1_score_b))\n",
    "\n",
    "    # vector model\n",
    "    precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "    f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "    print(f\"==================== result of vector model [ '{key}' ] ====================\")\n",
    "    print(f\"Precision: {precision_v:.2f}, Recall: {recall_v:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score_v:.2f}\\n\")\n",
    "    results_v.append((precision_v, recall_v, f1_score_v))\n",
    "\n",
    "# Average for boolean model\n",
    "# average_precision_b = sum([result[0] for result in results_b]) / len(results_b)\n",
    "# average_recall_b = sum([result[1] for result in results_b]) / len(results_b)\n",
    "# average_f1_score_b = sum([result[2] for result in results_b]) / len(results_b)\n",
    "\n",
    "# print(f\"Average Precision of boolean model: {average_precision_b:.2f}\")\n",
    "# print(f\"Average Recall of boolean model: {average_recall_b:.2f}\")\n",
    "# print(f\"Average F1 Score of boolean model: {average_f1_score_b:.2f}\\n\")\n",
    "\n",
    "# average_results_b = [average_precision_b, average_recall_b, average_f1_score_b]\n",
    "\n",
    "# Average for vector model\n",
    "average_precision_v = sum([result[0] for result in results_v]) / len(results_v)\n",
    "average_recall_v = sum([result[1] for result in results_v]) / len(results_v)\n",
    "average_f1_score_v = sum([result[2] for result in results_v]) / len(results_v)\n",
    "\n",
    "print(f\"Average Precision of vector model: {average_precision_v:.2f}\")\n",
    "print(f\"Average Recall of vector model: {average_recall_v:.2f}\")\n",
    "print(f\"Average F1 Score of vector model: {average_f1_score_v:.2f}\")\n",
    "\n",
    "average_results_v = [average_precision_v, average_recall_v, average_f1_score_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3426414a-7b68-4ced-b967-33732555ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori ohne svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cc3bb96-9444-4d43-b15f-b35ad0f963b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result of vector model [ '총선' ] ====================\n",
      "Precision: 0.41, Recall: 1.00\n",
      "F1 Score: 0.59\n",
      "\n",
      "==================== result of vector model [ '선거' ] ====================\n",
      "Precision: 0.36, Recall: 1.00\n",
      "F1 Score: 0.53\n",
      "\n",
      "==================== result of vector model [ '제22대_국회의원선거' ] ====================\n",
      "Precision: 0.03, Recall: 1.00\n",
      "F1 Score: 0.06\n",
      "\n",
      "==================== result of vector model [ '4월_10일_투표' ] ====================\n",
      "Precision: 0.00, Recall: 1.00\n",
      "F1 Score: 0.01\n",
      "\n",
      "==================== result of vector model [ '문장' ] ====================\n",
      "Precision: 0.00, Recall: 1.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Average Precision of vector model: 0.16\n",
      "Average Recall of vector model: 1.00\n",
      "Average F1 Score of vector model: 0.24\n"
     ]
    }
   ],
   "source": [
    "results_b, results_v = [], []\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    gt = set(ground_truths[key][0])\n",
    "    #boolean = set(boolean_results[key][0])\n",
    "    vector = set(vector_results[key][0])  \n",
    "\n",
    "    # boolean model\n",
    "    # precision_b, recall_b = calculate_precision_recall(gt, boolean)\n",
    "    # f1_score_b = calculate_f1_score(precision_b, recall_b)\n",
    "    # print(f\"==================== result of boolean model [ '{key}' ] ====================\")\n",
    "    # print(f\"Precision: {precision_b:.2f}, Recall: {recall_b:.2f}\")\n",
    "    # print(f\"F1 Score: {f1_score_b:.2f}\\n\")\n",
    "    # results_b.append((precision_b, recall_b, f1_score_b))\n",
    "\n",
    "    # vector model\n",
    "    precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "    f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "    print(f\"==================== result of vector model [ '{key}' ] ====================\")\n",
    "    print(f\"Precision: {precision_v:.2f}, Recall: {recall_v:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score_v:.2f}\\n\")\n",
    "    results_v.append((precision_v, recall_v, f1_score_v))\n",
    "\n",
    "# Average for boolean model\n",
    "# average_precision_b = sum([result[0] for result in results_b]) / len(results_b)\n",
    "# average_recall_b = sum([result[1] for result in results_b]) / len(results_b)\n",
    "# average_f1_score_b = sum([result[2] for result in results_b]) / len(results_b)\n",
    "\n",
    "# print(f\"Average Precision of boolean model: {average_precision_b:.2f}\")\n",
    "# print(f\"Average Recall of boolean model: {average_recall_b:.2f}\")\n",
    "# print(f\"Average F1 Score of boolean model: {average_f1_score_b:.2f}\\n\")\n",
    "\n",
    "# average_results_b = [average_precision_b, average_recall_b, average_f1_score_b]\n",
    "\n",
    "# Average for vector model\n",
    "average_precision_v = sum([result[0] for result in results_v]) / len(results_v)\n",
    "average_recall_v = sum([result[1] for result in results_v]) / len(results_v)\n",
    "average_f1_score_v = sum([result[2] for result in results_v]) / len(results_v)\n",
    "\n",
    "print(f\"Average Precision of vector model: {average_precision_v:.2f}\")\n",
    "print(f\"Average Recall of vector model: {average_recall_v:.2f}\")\n",
    "print(f\"Average F1 Score of vector model: {average_f1_score_v:.2f}\")\n",
    "\n",
    "average_results_v = [average_precision_v, average_recall_v, average_f1_score_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88d2fe55-f6a2-4178-a060-a86459adb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd 50 + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ee08e84-2974-4dc2-826a-64db41af019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "==================== result of vector model [ '총선' ] ====================\n",
      "Precision: 0.48, Recall: 0.98\n",
      "F1 Score: 0.65\n",
      "\n",
      "==================== result of vector model [ '선거' ] ====================\n",
      "Precision: 0.48, Recall: 0.94\n",
      "F1 Score: 0.63\n",
      "\n",
      "==================== result of vector model [ '제22대_국회의원선거' ] ====================\n",
      "Precision: 0.04, Recall: 1.00\n",
      "F1 Score: 0.07\n",
      "\n",
      "==================== result of vector model [ '4월_10일_투표' ] ====================\n",
      "Precision: 0.01, Recall: 1.00\n",
      "F1 Score: 0.02\n",
      "\n",
      "Average Precision of vector model: 0.25\n",
      "Average Recall of vector model: 0.98\n",
      "Average F1 Score of vector model: 0.34\n"
     ]
    }
   ],
   "source": [
    "label_data = ['datasets/총선.csv', 'datasets/선거.csv', 'datasets/제22대_국회의원선거.csv', 'datasets/4월_10일_투표.csv']\n",
    "#boolean_data = ['datasets/Boolean_총선.csv', 'datasets/Boolean_선거.csv', 'datasets/Boolean_제22대.csv', 'datasets/Boolean_410투표.csv', 'datasets/Boolean_문장.csv']\n",
    "vector_data = ['master/Vector_총선.csv', 'master/Vector_선거.csv', 'master/Vector_제22대.csv', 'master/Vector_410투표.csv']\n",
    "\n",
    "keys = ['총선', '선거', '제22대_국회의원선거', '4월_10일_투표']\n",
    "\n",
    "ground_truths = read_csv_to_dict(label_data, keys)\n",
    "#boolean_results = read_csv_to_dict(boolean_data, keys)\n",
    "vector_results = read_csv_to_dict(vector_data, keys)\n",
    "\n",
    "results_b, results_v = [], []\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    gt = set(ground_truths[key][0])\n",
    "    #boolean = set(boolean_results[key][0])\n",
    "    vector = set(vector_results[key][0])  \n",
    "\n",
    "    # boolean model\n",
    "    # precision_b, recall_b = calculate_precision_recall(gt, boolean)\n",
    "    # f1_score_b = calculate_f1_score(precision_b, recall_b)\n",
    "    # print(f\"==================== result of boolean model [ '{key}' ] ====================\")\n",
    "    # print(f\"Precision: {precision_b:.2f}, Recall: {recall_b:.2f}\")\n",
    "    # print(f\"F1 Score: {f1_score_b:.2f}\\n\")\n",
    "    # results_b.append((precision_b, recall_b, f1_score_b))\n",
    "\n",
    "    # vector model\n",
    "    precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "    f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "    print(f\"==================== result of vector model [ '{key}' ] ====================\")\n",
    "    print(f\"Precision: {precision_v:.2f}, Recall: {recall_v:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score_v:.2f}\\n\")\n",
    "    results_v.append((precision_v, recall_v, f1_score_v))\n",
    "\n",
    "# Average for boolean model\n",
    "# average_precision_b = sum([result[0] for result in results_b]) / len(results_b)\n",
    "# average_recall_b = sum([result[1] for result in results_b]) / len(results_b)\n",
    "# average_f1_score_b = sum([result[2] for result in results_b]) / len(results_b)\n",
    "\n",
    "# print(f\"Average Precision of boolean model: {average_precision_b:.2f}\")\n",
    "# print(f\"Average Recall of boolean model: {average_recall_b:.2f}\")\n",
    "# print(f\"Average F1 Score of boolean model: {average_f1_score_b:.2f}\\n\")\n",
    "\n",
    "# average_results_b = [average_precision_b, average_recall_b, average_f1_score_b]\n",
    "\n",
    "# Average for vector model\n",
    "average_precision_v = sum([result[0] for result in results_v]) / len(results_v)\n",
    "average_recall_v = sum([result[1] for result in results_v]) / len(results_v)\n",
    "average_f1_score_v = sum([result[2] for result in results_v]) / len(results_v)\n",
    "\n",
    "print(f\"Average Precision of vector model: {average_precision_v:.2f}\")\n",
    "print(f\"Average Recall of vector model: {average_recall_v:.2f}\")\n",
    "print(f\"Average F1 Score of vector model: {average_f1_score_v:.2f}\")\n",
    "\n",
    "average_results_v = [average_precision_v, average_recall_v, average_f1_score_v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de490763-3230-476f-aa59-0348d94b090a",
   "metadata": {},
   "source": [
    "# 다시 preprocess (stopwords 좀 더 넣음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b2e1c11-07b7-40d9-8e99-9414960c9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "Ignoring invalid date format: Date\n",
      "==================== result of vector model [ '총선' ] ====================\n",
      "Precision: 0.48, Recall: 0.98\n",
      "F1 Score: 0.65\n",
      "\n",
      "==================== result of vector model [ '선거' ] ====================\n",
      "Precision: 0.48, Recall: 0.94\n",
      "F1 Score: 0.63\n",
      "\n",
      "==================== result of vector model [ '제22대_국회의원선거' ] ====================\n",
      "Precision: 0.04, Recall: 1.00\n",
      "F1 Score: 0.07\n",
      "\n",
      "==================== result of vector model [ '4월_10일_투표' ] ====================\n",
      "Precision: 0.01, Recall: 1.00\n",
      "F1 Score: 0.02\n",
      "\n",
      "Average Precision of vector model: 0.25\n",
      "Average Recall of vector model: 0.98\n",
      "Average F1 Score of vector model: 0.34\n"
     ]
    }
   ],
   "source": [
    "label_data = ['datasets/총선.csv', 'datasets/선거.csv', 'datasets/제22대_국회의원선거.csv', 'datasets/4월_10일_투표.csv']\n",
    "#boolean_data = ['datasets/Boolean_총선.csv', 'datasets/Boolean_선거.csv', 'datasets/Boolean_제22대.csv', 'datasets/Boolean_410투표.csv', 'datasets/Boolean_문장.csv']\n",
    "vector_data = ['master/Vector_총선.csv', 'master/Vector_선거.csv', 'master/Vector_제22대.csv', 'master/Vector_410투표.csv']\n",
    "\n",
    "keys = ['총선', '선거', '제22대_국회의원선거', '4월_10일_투표']\n",
    "\n",
    "ground_truths = read_csv_to_dict(label_data, keys)\n",
    "#boolean_results = read_csv_to_dict(boolean_data, keys)\n",
    "vector_results = read_csv_to_dict(vector_data, keys)\n",
    "\n",
    "results_b, results_v = [], []\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    gt = set(ground_truths[key][0])\n",
    "    #boolean = set(boolean_results[key][0])\n",
    "    vector = set(vector_results[key][0])  \n",
    "\n",
    "    # boolean model\n",
    "    # precision_b, recall_b = calculate_precision_recall(gt, boolean)\n",
    "    # f1_score_b = calculate_f1_score(precision_b, recall_b)\n",
    "    # print(f\"==================== result of boolean model [ '{key}' ] ====================\")\n",
    "    # print(f\"Precision: {precision_b:.2f}, Recall: {recall_b:.2f}\")\n",
    "    # print(f\"F1 Score: {f1_score_b:.2f}\\n\")\n",
    "    # results_b.append((precision_b, recall_b, f1_score_b))\n",
    "\n",
    "    # vector model\n",
    "    precision_v, recall_v = calculate_precision_recall(gt, vector)\n",
    "    f1_score_v = calculate_f1_score(precision_v, recall_v)\n",
    "    print(f\"==================== result of vector model [ '{key}' ] ====================\")\n",
    "    print(f\"Precision: {precision_v:.2f}, Recall: {recall_v:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score_v:.2f}\\n\")\n",
    "    results_v.append((precision_v, recall_v, f1_score_v))\n",
    "\n",
    "# Average for boolean model\n",
    "# average_precision_b = sum([result[0] for result in results_b]) / len(results_b)\n",
    "# average_recall_b = sum([result[1] for result in results_b]) / len(results_b)\n",
    "# average_f1_score_b = sum([result[2] for result in results_b]) / len(results_b)\n",
    "\n",
    "# print(f\"Average Precision of boolean model: {average_precision_b:.2f}\")\n",
    "# print(f\"Average Recall of boolean model: {average_recall_b:.2f}\")\n",
    "# print(f\"Average F1 Score of boolean model: {average_f1_score_b:.2f}\\n\")\n",
    "\n",
    "# average_results_b = [average_precision_b, average_recall_b, average_f1_score_b]\n",
    "\n",
    "# Average for vector model\n",
    "average_precision_v = sum([result[0] for result in results_v]) / len(results_v)\n",
    "average_recall_v = sum([result[1] for result in results_v]) / len(results_v)\n",
    "average_f1_score_v = sum([result[2] for result in results_v]) / len(results_v)\n",
    "\n",
    "print(f\"Average Precision of vector model: {average_precision_v:.2f}\")\n",
    "print(f\"Average Recall of vector model: {average_recall_v:.2f}\")\n",
    "print(f\"Average F1 Score of vector model: {average_f1_score_v:.2f}\")\n",
    "\n",
    "average_results_v = [average_precision_v, average_recall_v, average_f1_score_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fa4164be-1c4c-4f12-a7ec-d7917cebbdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526813880126182"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_b[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f622fb0-4350-41db-8fef-802baa0b2029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024/02/06',\n",
       " '2024/03/17',\n",
       " '2024/03/25',\n",
       " '2024/02/23',\n",
       " '2024/04/03',\n",
       " '2024/02/18',\n",
       " '2024/04/06',\n",
       " '2024/01/11',\n",
       " '2024/03/05',\n",
       " '2024/02/27']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean = set(boolean_results['선거'][1])\n",
    "boolean_top_10_articles = list(boolean)[:10]\n",
    "boolean_top_10_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2c370cdb-a929-4493-98f1-92cb5ea305c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'총선'의 평균 시간 관련성 점수: 0.0540\n",
      "'선거'의 평균 시간 관련성 점수: 0.0540\n",
      "'제22대_국회의원선거'의 평균 시간 관련성 점수: 0.0657\n",
      "'4월_10일_투표'의 평균 시간 관련성 점수: 0.2000\n",
      "'문장'의 평균 시간 관련성 점수: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 2024년 4월 10일을 기준으로 시간 관련성 가중치 계산\n",
    "def calculate_time_relevance_weight(publication_date):\n",
    "    publication_datetime = datetime.strptime(publication_date, '%Y/%m/%d')\n",
    "    reference_datetime = datetime(2024, 4, 10)  # 2024년 4월 10일을 기준으로 설정\n",
    "    \n",
    "    # 2024년 4월 10일을 기준으로 발행일과의 시간 차이 계산\n",
    "    days_since_publication = (reference_datetime - publication_datetime).days\n",
    "    \n",
    "    # 최신성에 따라 가중치 계산 \n",
    "    if days_since_publication < 0:\n",
    "        return 0  # 발행일이 미래인 경우 가중치는 0\n",
    "    \n",
    "    weight = 1 / (days_since_publication + 1)  # 최신성에 따라 가중치 계산\n",
    "    return weight\n",
    "\n",
    "# 각 키별로 시간 관련성 점수 계산\n",
    "time_relevance_scores = {}\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    boolean = set(boolean_results[key][1])\n",
    "    boolean_top_10_articles = list(boolean)[:10]\n",
    "    ############################ 위에 바꿔야댐 데이터가 아직 안와서 임의로################\n",
    "    '''\n",
    "    ['2024/02/06',\n",
    "     '2024/03/17',\n",
    "     '2024/03/25',\n",
    "     '2024/02/23',\n",
    "     '2024/04/03',\n",
    "     '2024/02/18',\n",
    "     '2024/04/06',\n",
    "     '2024/01/11',\n",
    "     '2024/03/05',\n",
    "     '2024/02/27']\n",
    " '''\n",
    "    # 상위 기사들의 시간 관련성 점수 계산\n",
    "    time_relevance_scores[key] = 0  \n",
    "    \n",
    "    for article_date in boolean_top_10_articles:\n",
    "        time_weight = calculate_time_relevance_weight(article_date)\n",
    "        time_relevance_scores[key] += time_weight\n",
    "\n",
    "# 각 키별로 계산된 시간 관련성 점수 출력\n",
    "for key, score in time_relevance_scores.items():\n",
    "    print(f\"'{key}'의 시간 관련성 점수: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "233624ca-8049-4b9a-9f74-e22b7f6e309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024/02/06',\n",
       " '2024/03/17',\n",
       " '2024/03/25',\n",
       " '2024/02/23',\n",
       " '2024/04/03',\n",
       " '2024/02/18',\n",
       " '2024/04/06',\n",
       " '2024/01/11',\n",
       " '2024/03/05',\n",
       " '2024/02/27']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    boolean = set(boolean_results['총선'][1])\n",
    "    boolean_top_10_articles = list(boolean)[:10]\n",
    "    boolean_top_10_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f7853383-cb00-4191-9168-c1a78ad221bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015873015873015872, 0.043478260869565216, 0.06666666666666667, 0.021739130434782608, 0.16666666666666666, 0.0196078431372549, 0.3333333333333333, 0.011235955056179775, 0.02857142857142857, 0.023809523809523808]\n",
      "[0.015873015873015872, 0.043478260869565216, 0.06666666666666667, 0.021739130434782608, 0.16666666666666666, 0.0196078431372549, 0.3333333333333333, 0.011235955056179775, 0.02857142857142857, 0.023809523809523808]\n",
      "[0.25, 0.16666666666666666, 0.027777777777777776, 0.015151515151515152, 0.0196078431372549, 0.3333333333333333, 0.011235955056179775, 0.014084507042253521, 0.058823529411764705, 0.030303030303030304]\n",
      "[0.3333333333333333]\n",
      "[]\n",
      "'총선'의 평균 시간 관련성 점수: 0.0731\n",
      "'선거'의 평균 시간 관련성 점수: 0.0731\n",
      "'제22대_국회의원선거'의 평균 시간 관련성 점수: 0.0927\n",
      "'4월_10일_투표'의 평균 시간 관련성 점수: 0.3333\n",
      "'문장'의 평균 시간 관련성 점수: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 2024년 4월 10일을 기준으로 시간 관련성 가중치 계산\n",
    "def calculate_time_relevance_weight(publication_date):\n",
    "    publication_datetime = datetime.strptime(publication_date, '%Y/%m/%d')\n",
    "    reference_datetime = datetime(2024, 4, 8)  # 2024년 4월 10일을 기준으로 설정\n",
    "    \n",
    "    # 2024년 4월 10일을 기준으로 발행일과의 시간 차이 계산\n",
    "    days_since_publication = (reference_datetime - publication_datetime).days\n",
    "    \n",
    "    # 최신성에 따라 가중치 계산 \n",
    "    if days_since_publication < 0:\n",
    "        return 0  # 발행일이 미래인 경우 가중치는 0\n",
    "    \n",
    "    weight = 1 / (days_since_publication + 1)  # 최신성에 따라 가중치 계산\n",
    "    ################ 사실 패널티?\n",
    "    return weight\n",
    "\n",
    "# 각 키별로 시간 관련성 점수 계산\n",
    "time_relevance_scores = {}\n",
    "\n",
    "for key in ground_truths.keys():\n",
    "    boolean = set(boolean_results[key][1])\n",
    "    boolean_top_10_articles = list(boolean)[:10]\n",
    "    \n",
    "    # 상위 기사들의 시간 관련성 점수 계산\n",
    "    key_time_relevance_scores = []\n",
    "    \n",
    "    for article_date in boolean_top_10_articles:\n",
    "        time_weight = calculate_time_relevance_weight(article_date)\n",
    "        key_time_relevance_scores.append(time_weight)\n",
    "    \n",
    "    # 각 키별로 계산된 시간 관련성 점수를 리스트에 저장\n",
    "    time_relevance_scores[key] = key_time_relevance_scores\n",
    "    print(time_relevance_scores[key])\n",
    "          \n",
    "# 각 키별로 계산된 시간 관련성 점수의 평균 계산\n",
    "average_time_relevance_scores = {}\n",
    "\n",
    "for key, scores in time_relevance_scores.items():\n",
    "    if scores:  # 해당 키의 시간 관련성 점수 리스트가 비어있지 않은 경우\n",
    "        average_score = sum(scores) / len(scores)\n",
    "    else:\n",
    "        average_score = 0  # 점수 리스트가 비어있는 경우 0으로 처리\n",
    "        \n",
    "    average_time_relevance_scores[key] = average_score\n",
    "\n",
    "# 각 키별로 계산된 평균 시간 관련성 점수 출력\n",
    "for key, average_score in average_time_relevance_scores.items():\n",
    "    print(f\"'{key}'의 평균 시간 관련성 점수: {average_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a680b2b1-6b1a-4dad-bb88-ce106c837265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Metric for '총선': 0.6168\n",
      "Combined Metric for '선거': 0.4062\n",
      "Combined Metric for '제22대_국회의원선거': 0.2605\n",
      "Combined Metric for '4월_10일_투표': 0.1362\n",
      "Combined Metric for '문장': 0.0000\n",
      "0.2839431123445969\n"
     ]
    }
   ],
   "source": [
    "def calculate_combined_metric(f1_score, time_relevance_score, alpha=0.5, beta=0.5):\n",
    "    combined_score = alpha * f1_score + beta * time_relevance_score\n",
    "    return combined_score\n",
    "\n",
    "# 예시: F1 스코어와 시간 관련성 점수\n",
    "f1_score = results_b[0][2]  # 예시로 첫 번째 결과의 F1 스코어를 가져옴\n",
    "results = []\n",
    "\n",
    "# 새로운 메트릭 계산 (가중 평균)\n",
    "for i, key in enumerate(ground_truths.keys()):\n",
    "    combined_metric = calculate_combined_metric(results_b[i][2], average_time_relevance_scores[key], alpha=0.8, beta=0.2)\n",
    "    print(f\"Combined Metric for '{key}': {combined_metric:.4f}\")\n",
    "    results.append(combined_metric)\n",
    "\n",
    "## 이것들을 산술평균 내면 (average) 모델의 종합 accuracy가 나온다!\n",
    "average_combined = sum([result for result in results]) / len(results)\n",
    "print(average_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1217442d-79d4-418c-b3fd-112ea0fbbec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3263174847304964"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_f1_score_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a4c1d7ba-348c-4c36-bf58-4ade841efa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2839431123445969"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e18e82-60fa-4c9c-9470-589d71489c9d",
   "metadata": {},
   "source": [
    "# 현재 제대로 된 vector model result를 가지고 오지 않았기에... 너무 점수들이 낮으면 f1 score 가중치 올리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a5973-b596-4980-97f2-45ee72eefc5d",
   "metadata": {},
   "source": [
    "https://blog.naver.com/ycpiglet/223060257019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
